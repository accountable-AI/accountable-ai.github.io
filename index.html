---
layout: default
title: Accountable AI
---
<div class="blurb">
	<h1>Module description</h1>
		<p>This course will provide students with interdisciplinary approaches to understand the social and ethical effects of the ubiquitous deployment of AI technology and Machine Learning. This includes (but is not limited to) biases in data processing, surveillance, privacy, misrepresentation, and recourse. Machine Learning and AI systems seem to generate “automated decisions”, but people are central at every step of the lifecycle: defining tasks, generating datasets, preprocessing and labelling, which models to use, what to optimize, and so on. We will engage with the socio-technical nature of these issues in order to think through the needs for accountable and human-centered AI. We also critically investigate the regimes of knowledge in computer science when dealing with AI accountability.
		<br>					
		We will start with contemporary and intersectional foundations in ethics, and then move to the current and growing research literature on ethics in AI, before considering specific AI tasks, data sets and methodologies through the lens of the ethical considerations identified. The weekly discussions are grounded in the implementation of AI in “data life”: the everyday interactions of citizens with predictive AI technology and big data. In doing so, students will become acquainted with different perspectives on AI accountability. This incudes ethical orientations towards accountability, legal frameworks for AI implementation, and computational methods for fairness and transparency.
		<br>	
		Students will learn to formulate an interdisciplinary perspective on AI through multiple theoretical frameworks grounded in technical and humanistic perspectives, and to construct and explain logical arguments about AI in relation to significant issues in studies of technology, data ethics, literature, culture, and society. The course will feature guest lecturers from different disciplinary backgrounds to ensure a diversity of standpoints, voices and concerns.</p>
		</div>

<div class="blurb">
	<h1>Assessment</h1>
	
	The module is assessed based on a weekly blog post (300w, 30%) in which you detail your daily experiences with AI technology from a perspective of ethics and accountability. 
	<br>
	For the final assignment of 4,000 words (70%), you have two options. 

	<ul>
        <li>A paper analyzing some particular AI system or data set in terms of the concepts developed, and looking forward to how ethical best practices could be developed for that task or dataset. In the paper, you will ask questions such as “what went wrong?” and “who was harmed?”, but also “who benefitted?” and “how could we mitigate his kind of harm in the future?” from ethical, legal, and technical perspectives.
</li>
        <li>An essay dealing with the future of accountable AI. Using academic sources, construct an argument about the future of AI from an ethical point of view. Using a particular example of AI, either defend or challenge this use of AI, and offer arguments regarding future developments of this particular use case. Think specifically about the ways in which the system can be made more accountable from the perspective of individual users, and what kinds of dangers or challenges lie ahead.
</li>
	</ul>
	</div>

<div class="blurb">
<h1>Module Materials and Student Participation</h1>
Readings, lecture slides, notes, will be available on the module’s KEATS page. Each session will have several dedicated readings, will we will approach using a ‘divide and share’ tactic: everyone reads something else, with the same questions in mind. You will generally be asked to pick readings that offer a different perspectives to your own. During seminars, you will share your findings with the rest of class based on the questions for each week (see below). 
</div>


<h2>For the full concept syllabus, see <a href="https://github.com/accountable-AI/accountable-ai.github.io/blob/main/accountable_ai_syllabus.pdf">here</a></h2>




